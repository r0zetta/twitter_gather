{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gather_analysis_helper import *\n",
    "from twitter_no_rl_tool import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tweets_from_counter(cnt, num, offset=0):\n",
    "    gather = num + offset\n",
    "    snl = [x for x, c in cnt.most_common(gather)]\n",
    "    snl = snl[offset:]\n",
    "    for sn in snl:\n",
    "        if sn in sn_twid:\n",
    "            twidl = sn_twid[sn]\n",
    "            tw = None\n",
    "            tries = 0\n",
    "            while tw == None and tries < 5:\n",
    "                rtwid = random.choice(list(twidl))\n",
    "                url = twid_url[rtwid]\n",
    "                tw = Tweet(url)\n",
    "                tries += 1\n",
    "            display(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = False\n",
    "num_plots = 5\n",
    "plot_timespan = 7 * 24\n",
    "num_counters = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"analysis_live\"\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_span = plot_timespan\n",
    "current_unix = get_utc_unix_time()\n",
    "start_time = unix_time_to_readable(current_unix - (3600*analysis_span))\n",
    "end_time = unix_time_to_readable(current_unix + (3600*3))\n",
    "\n",
    "#start_time = \"2017-01-01 00:00:00\"\n",
    "#end_time = \"2022-01-01 00:00:00\"\n",
    "\n",
    "print(\"Start time: \" + start_time)\n",
    "print(\"End time: \" + end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = make_file_iterator(start_time, end_time, os.path.join(\"data/raw.json\"))\n",
    "full = get_counters_and_interactions2(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf = full[\"user_fields\"]\n",
    "counters = full[\"counters\"]\n",
    "users = counters[\"users\"]\n",
    "sn_rsn = full[\"sn_rsn\"]\n",
    "rsn_sn = full[\"rsn_sn\"]\n",
    "sn_rep = full[\"sn_rep\"]\n",
    "rep_sn = full[\"rep_sn\"]\n",
    "sn_men = full[\"sn_men\"]\n",
    "men_sn = full[\"men_sn\"]\n",
    "sn_quo = full[\"sn_quo\"]\n",
    "quo_sn = full[\"quo_sn\"]\n",
    "rsn_twid = full[\"rsn_twid\"]\n",
    "twid_count = full[\"twid_count\"]\n",
    "twid_rt_count = full[\"twid_rt_count\"]\n",
    "twid_text = full[\"twid_text\"]\n",
    "twid_url = full[\"twid_url\"]\n",
    "twid_sn = full[\"twid_sn\"]\n",
    "sn_twid = full[\"sn_twid\"]\n",
    "sn_details = full[\"sn_details\"]\n",
    "sn_hashtag = full[\"sn_hashtag\"]\n",
    "hashtag_sn = full[\"hashtag_sn\"]\n",
    "hashtag_twid = full[\"hashtag_twid\"]\n",
    "orig_twids = full[\"orig_twids\"]\n",
    "replied_twids = full[\"replied_twids\"]\n",
    "quoted_twids = full[\"quoted_twids\"]\n",
    "retweeted_twids = full[\"retweeted_twids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show language distribution\n",
    "cluster_hts = counters[\"lang\"]\n",
    "\n",
    "plot_data = {}\n",
    "plot_data[\"labels\"] = []\n",
    "plot_data[\"sizes\"] = []\n",
    "\n",
    "n = 10\n",
    "other = 0\n",
    "otherc = 0\n",
    "for ht, c in cluster_hts.most_common():\n",
    "    if len(plot_data[\"labels\"]) <= n:\n",
    "        plot_data[\"labels\"].append(ht + \" (\" + str(counters[\"lang\"][ht]) + \")\")\n",
    "        plot_data[\"sizes\"].append(c)\n",
    "    else:\n",
    "        otherc += 1\n",
    "        other += c\n",
    "plot_data[\"labels\"].append(\"Other (\" + str(other) + \")\")\n",
    "plot_data[\"sizes\"].append(other)\n",
    "\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title(\"Languages\")\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=30)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_start = unix_time_to_readable(full[\"oldest\"])\n",
    "collect_end = unix_time_to_readable(full[\"newest\"])\n",
    "print(\"Collection started on \" + collect_start + \" and ended on \" + collect_end)\n",
    "\n",
    "timespan_s = full[\"timespan\"]\n",
    "timespan_h = timespan_s/3600\n",
    "timespan_d = timespan_h/24\n",
    "high_vol = timespan_d*40\n",
    "print(\"Collection duration: \" + \"%.2f\"%timespan_d + \" days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot recent activity within the collected data (tweets per hour)\n",
    "num_hours = analysis_span\n",
    "plot_data = full[\"ts_data\"]\n",
    "plot_data = trim_plot_data(plot_data, 0, num_hours)\n",
    "height = len(plot_data[\"count\"])/3\n",
    "sns.set(rc={'figure.figsize':(20,height)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure()\n",
    "ax = sns.barplot(y=\"time\", x=\"count\", palette=\"husl\", data=plot_data)\n",
    "for i, v in enumerate(plot_data[\"count\"]):\n",
    "    ax.text(v+1, i+0.25, str(v), fontweight='bold')\n",
    "ax.set_title(\"Activity over the last \" + str(num_hours) + \" hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I save some of the data in a format that gephi can eat\n",
    "save_csv(sn_rsn, os.path.join(dirname, \"retweet_interactions.csv\"))\n",
    "save_csv(sn_rep, os.path.join(dirname, \"reply_interactions.csv\"))\n",
    "save_csv(sn_men, os.path.join(dirname, \"mention_interactions.csv\"))\n",
    "save_csv(sn_quo, os.path.join(dirname, \"quote_interactions.csv\"))\n",
    "save_json(sn_rsn, os.path.join(dirname, \"sn_rsn.json\"))\n",
    "save_json(rsn_sn, os.path.join(dirname, \"rsn_sn.json\"))\n",
    "save_json(counters[\"retweeters\"], os.path.join(dirname, \"retweeters.json\"))\n",
    "save_json(counters[\"retweeted\"], os.path.join(dirname, \"retweeted.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function just prints some statistics about the dataset\n",
    "print_counters(counters, uf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_sn_counter(counters[\"susp_users\"], 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for twid in full[\"susp_twids\"]:\n",
    "    text = twid_text[twid]\n",
    "    url = twid_url[twid]\n",
    "    print(twid + \"\\t\" + text + \"\\t\" + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stlen =  len(full[\"susp_twids\"])\n",
    "if stlen > 0:\n",
    "    for twid in random.sample(list(full[\"susp_twids\"]), min(10, stlen)):\n",
    "        url = twid_url[twid]\n",
    "        display(Tweet(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_tweets_from_counter(counters[\"susp_users\"], 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate CTM for hashtags\n",
    "susp_hashtags = []\n",
    "print(\"Hashtag                         | Count | RTC   | U     | R     | F     | C  \")\n",
    "print(\"================================================================================\")\n",
    "for hashtag, total_ht in counters[\"hashtags\"].most_common():\n",
    "    if total_ht < 200:\n",
    "        continue\n",
    "    # 1. Calculate the average number of posts per user for an item (U)\n",
    "    U = 0\n",
    "    if hashtag in hashtag_sn:\n",
    "        ht_post_counts = []\n",
    "        for sn, c in hashtag_sn[hashtag].items():\n",
    "            ht_post_counts.append(c)\n",
    "        U = np.mean(ht_post_counts)\n",
    "        \n",
    "    # 2. Calculate the ratio of original tweets to retweets for an item (R)\n",
    "    R = 0\n",
    "    orig_ht_count = 0\n",
    "    rt_ht_count = 0\n",
    "    if hashtag in hashtag_twid:\n",
    "        twid_l = [x for x, c in hashtag_twid[hashtag].items()]\n",
    "        for twid in twid_l:\n",
    "            if twid in retweeted_twids:\n",
    "                rt_ht_count += twid_count[twid]\n",
    "            else:\n",
    "                orig_ht_count += twid_count[twid]\n",
    "    if rt_ht_count > 0:\n",
    "        R = rt_ht_count/total_ht * 100\n",
    "\n",
    "    # 3. Calculate the percentage of posts from the top 50 users (F)\n",
    "    num_top50_posts = 0\n",
    "    for sn, c in hashtag_sn[hashtag].most_common(50):\n",
    "        num_top50_posts += c\n",
    "    F = num_top50_posts/total_ht\n",
    "    \n",
    "    # 4. C = R/10 + F + U\n",
    "    C = R/10 + F + U\n",
    "\n",
    "    if C > 12:\n",
    "        susp_hashtags.append(hashtag)\n",
    "        hashtag = \"(*) \" + hashtag\n",
    "    \n",
    "    sep = \"\\t\"\n",
    "    if len(hashtag) < 24:\n",
    "        sep += \"\\t\"\n",
    "    if len(hashtag) < 16:\n",
    "        sep += \"\\t\"\n",
    "    if len(hashtag) < 8:\n",
    "        sep += \"\\t\"\n",
    "    msg = hashtag + sep + \"|\"\n",
    "    msg += str(orig_ht_count) + \"\\t|\"\n",
    "    msg += str(rt_ht_count) + \"\\t|\"\n",
    "    msg += \"%.2f\"%U + \"\\t|\"\n",
    "    msg += \"%.2f\"%R + \"\\t|\"\n",
    "    msg += \"%.2f\"%F + \"\\t|\"\n",
    "    msg += \"%.2f\"%C + \"\\t\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susp_ht_users = Counter()\n",
    "for ht in susp_hashtags:\n",
    "    if ht in hashtag_sn:\n",
    "        snc = hashtag_sn[ht]\n",
    "        for x, c in snc.items():\n",
    "            susp_ht_users[x] += c\n",
    "print(len(susp_ht_users))\n",
    "\n",
    "susp_ht_twids = Counter()\n",
    "for ht in susp_hashtags:\n",
    "    if ht in hashtag_twid:\n",
    "        twidc = hashtag_twid[ht]\n",
    "        for x, c in twidc.items():\n",
    "            susp_ht_twids[x] += c\n",
    "print(len(susp_ht_twids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_tweets_from_counter(susp_ht_users, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for twid, c in susp_ht_twids.most_common(20):\n",
    "    text = twid_text[twid]\n",
    "    url = twid_url[twid]\n",
    "    print(str(c) + \"\\t\" + twid + \"\\t\" + text + \"\\t\" + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(susp_ht_twids) > 0:\n",
    "    sample_len = 10\n",
    "    if len(susp_ht_twids) < sample_len:\n",
    "        sample_len = len(susp_ht_twids)\n",
    "    for twid in random.sample(list([x for x, c in susp_ht_twids.items()]), sample_len):\n",
    "        url = twid_url[twid]\n",
    "        display(Tweet(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show account age distribution\n",
    "all_acct_ages = Counter()\n",
    "for sn, d in sn_details.items():\n",
    "    if \"created_at\" in d:\n",
    "        ca = d[\"created_at\"]\n",
    "        yr = ca[-4:]\n",
    "        mon = md[ca[4:7]]\n",
    "        q = \"\"\n",
    "        for qname, qvals in quarters.items():\n",
    "            if int(mon) in qvals:\n",
    "                q = qname\n",
    "        day = ca[8:10]\n",
    "        ds = str(yr) + \"-\" + q\n",
    "        all_acct_ages[ds] += 1\n",
    "plot_data = {}\n",
    "plot_data[\"labels\"] = []\n",
    "plot_data[\"counts\"] = []\n",
    "for label, count in sorted(all_acct_ages.items(), reverse=True):\n",
    "    plot_data[\"labels\"].append(label)\n",
    "    plot_data[\"counts\"].append(count)\n",
    "plot_data = trim_plot_data(plot_data, 0, 50)\n",
    "height = len(plot_data[\"counts\"])/3\n",
    "sns.set(rc={'figure.figsize':(20,height)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax = sns.barplot(x=\"counts\", y=\"labels\", palette=\"husl\", data=plot_data)\n",
    "for i, v in enumerate(plot_data[\"counts\"]):\n",
    "    pad = min(1.0, v/100)\n",
    "    ax.text(v+pad, i+0.25, str(v), fontweight='bold')\n",
    "ax.set_title(\"Account ages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show account age distribution of suspicious users\n",
    "susp_set = set([x for x, c in full[\"counters\"][\"susp_users\"].most_common()])\n",
    "all_acct_ages = Counter()\n",
    "for sn, d in sn_details.items():\n",
    "    if sn not in susp_set:\n",
    "        continue\n",
    "    if \"created_at\" in d:\n",
    "        ca = d[\"created_at\"]\n",
    "        yr = ca[-4:]\n",
    "        mon = md[ca[4:7]]\n",
    "        q = \"\"\n",
    "        for qname, qvals in quarters.items():\n",
    "            if int(mon) in qvals:\n",
    "                q = qname\n",
    "        day = ca[8:10]\n",
    "        ds = str(yr) + \"-\" + q\n",
    "        all_acct_ages[ds] += 1\n",
    "plot_data = {}\n",
    "plot_data[\"labels\"] = []\n",
    "plot_data[\"counts\"] = []\n",
    "for label, count in sorted(all_acct_ages.items(), reverse=True):\n",
    "    plot_data[\"labels\"].append(label)\n",
    "    plot_data[\"counts\"].append(count)\n",
    "plot_data = trim_plot_data(plot_data, 0, 50)\n",
    "height = len(plot_data[\"counts\"])/3\n",
    "sns.set(rc={'figure.figsize':(20,height)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax = sns.barplot(x=\"counts\", y=\"labels\", palette=\"husl\", data=plot_data)\n",
    "for i, v in enumerate(plot_data[\"counts\"]):\n",
    "    pad = min(1.0, v/100)\n",
    "    ax.text(v+pad, i+0.25, str(v), fontweight='bold')\n",
    "ax.set_title(\"Suspicious user account ages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show account age distribution of suspicious users\n",
    "if len(susp_ht_users) > 0:\n",
    "    susp_set = set([x for x, c in susp_ht_users.most_common()])\n",
    "    all_acct_ages = Counter()\n",
    "    for sn, d in sn_details.items():\n",
    "        if sn not in susp_set:\n",
    "            continue\n",
    "        if \"created_at\" in d:\n",
    "            ca = d[\"created_at\"]\n",
    "            yr = ca[-4:]\n",
    "            mon = md[ca[4:7]]\n",
    "            q = \"\"\n",
    "            for qname, qvals in quarters.items():\n",
    "                if int(mon) in qvals:\n",
    "                    q = qname\n",
    "            day = ca[8:10]\n",
    "            ds = str(yr) + \"-\" + q\n",
    "            all_acct_ages[ds] += 1\n",
    "    plot_data = {}\n",
    "    plot_data[\"labels\"] = []\n",
    "    plot_data[\"counts\"] = []\n",
    "    for label, count in sorted(all_acct_ages.items(), reverse=True):\n",
    "        plot_data[\"labels\"].append(label)\n",
    "        plot_data[\"counts\"].append(count)\n",
    "    plot_data = trim_plot_data(plot_data, 0, 50)\n",
    "    height = len(plot_data[\"counts\"])/3\n",
    "    sns.set(rc={'figure.figsize':(20,height)})\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    ax = sns.barplot(x=\"counts\", y=\"labels\", palette=\"husl\", data=plot_data)\n",
    "    for i, v in enumerate(plot_data[\"counts\"]):\n",
    "        pad = min(1.0, v/100)\n",
    "        ax.text(v+pad, i+0.25, str(v), fontweight='bold')\n",
    "    ax.set_title(\"Suspicious hashtag user account ages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some hashtags\n",
    "cluster_hts = counters[\"hashtags\"]\n",
    "\n",
    "plot_data = {}\n",
    "plot_data[\"labels\"] = []\n",
    "plot_data[\"sizes\"] = []\n",
    "\n",
    "n = 25\n",
    "other = 0\n",
    "otherc = 0\n",
    "for ht, c in cluster_hts.most_common():\n",
    "    if len(plot_data[\"labels\"]) <= n:\n",
    "        plot_data[\"labels\"].append(\"#\" + ht + \" (\" + str(counters[\"hashtags\"][ht]) + \")\")\n",
    "        plot_data[\"sizes\"].append(c)\n",
    "    else:\n",
    "        otherc += 1\n",
    "        other += c\n",
    "plot_data[\"labels\"].append(\"Other (\" + str(other) + \")\")\n",
    "plot_data[\"sizes\"].append(other)\n",
    "\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title(\"Hashtags\")\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=0)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some hashtags\n",
    "susp_ht_all = Counter()\n",
    "for sn in susp_ht_users:\n",
    "    if sn in sn_hashtag:\n",
    "        for x, c in sn_hashtag[sn].items():\n",
    "            susp_ht_all[x] += c\n",
    "cluster_hts = susp_ht_all\n",
    "\n",
    "plot_data = {}\n",
    "plot_data[\"labels\"] = []\n",
    "plot_data[\"sizes\"] = []\n",
    "\n",
    "n = 25\n",
    "other = 0\n",
    "otherc = 0\n",
    "for ht, c in cluster_hts.most_common():\n",
    "    if len(plot_data[\"labels\"]) <= n:\n",
    "        plot_data[\"labels\"].append(\"#\" + ht + \" (\" + str(susp_ht_all[ht]) + \")\")\n",
    "        plot_data[\"sizes\"].append(c)\n",
    "    else:\n",
    "        otherc += 1\n",
    "        other += c\n",
    "plot_data[\"labels\"].append(\"Other (\" + str(other) + \")\")\n",
    "plot_data[\"sizes\"].append(other)\n",
    "\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title(\"Hashtags\")\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=0)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some hashtags\n",
    "cluster_hts = counters[\"retweeted\"]\n",
    "\n",
    "plot_data = {}\n",
    "plot_data[\"labels\"] = []\n",
    "plot_data[\"sizes\"] = []\n",
    "\n",
    "n = 25\n",
    "other = 0\n",
    "otherc = 0\n",
    "for ht, c in cluster_hts.most_common():\n",
    "    if len(plot_data[\"labels\"]) <= n:\n",
    "        plot_data[\"labels\"].append(ht + \" (\" + str(counters[\"retweeted\"][ht]) + \")\")\n",
    "        plot_data[\"sizes\"].append(c)\n",
    "    else:\n",
    "        otherc += 1\n",
    "        other += c\n",
    "plot_data[\"labels\"].append(\"Other (\" + str(other) + \")\")\n",
    "plot_data[\"sizes\"].append(other)\n",
    "\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title(\"Retweeted\")\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some url domains\n",
    "domains = counters[\"domains\"]\n",
    "cluster_hts = domains\n",
    "plot_data = {}\n",
    "plot_data[\"labels\"] = []\n",
    "plot_data[\"sizes\"] = []\n",
    "\n",
    "n = 40\n",
    "other = 0\n",
    "otherc = 0\n",
    "for ht, c in cluster_hts.most_common():\n",
    "    if len(plot_data[\"labels\"]) <= n:\n",
    "        plot_data[\"labels\"].append(ht + \" (\" + str(counters[\"domains\"][ht]) + \")\")\n",
    "        plot_data[\"sizes\"].append(c)\n",
    "    else:\n",
    "        otherc += 1\n",
    "        other += c\n",
    "plot_data[\"labels\"].append(\"Other (\" + str(other) + \")\")\n",
    "plot_data[\"sizes\"].append(other)\n",
    "\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title(\"Domains\")\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_domains = [x for x, c in domains.most_common(num_plots)]\n",
    "min_r = 1\n",
    "dc = \"\"\n",
    "for url_target in top_domains:\n",
    "    msg = \"Users that used url containing: \" + url_target\n",
    "    msg += \" that tweeted them at least \" + str(min_r) + \" times\"\n",
    "    if len(dc) > 0:\n",
    "        msg += \" and whose account was created after \" + dc\n",
    "    msg += \".\"\n",
    "    print(msg)\n",
    "    amps = print_url_amplifiers(url_target, full,  min_retweets=min_r, date_cutoff=dc)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a heatmap of retweet overlaps\n",
    "mapping = rsn_sn\n",
    "overlaps = get_mapping_overlaps(mapping, 0, 20)\n",
    "hm_labels = []\n",
    "hm_items = []\n",
    "hm_data = []\n",
    "for label, oc in sorted(overlaps.items()):\n",
    "    hm_labels.append(label[:8])\n",
    "    hm_items.append(label)\n",
    "for item in hm_items:\n",
    "    row = [c for x, c in sorted(overlaps[item].items())]\n",
    "    hm_data.append(row)\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "hm = np.array(hm_data)\n",
    "plt.figure()\n",
    "ax = sns.heatmap(hm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=False, xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.set_title(\"Retweet overlaps (those who retweeted A also retweeted B)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a heatmap of cluster overlaps\n",
    "mapping = hashtag_sn\n",
    "overlaps = get_mapping_overlaps(mapping, 0, 20)\n",
    "hm_labels = []\n",
    "hm_items = []\n",
    "hm_data = []\n",
    "for label, oc in sorted(overlaps.items()):\n",
    "    hm_labels.append(label[:8])\n",
    "    hm_items.append(label)\n",
    "for item in hm_items:\n",
    "    row = [c for x, c in sorted(overlaps[item].items())]\n",
    "    hm_data.append(row)\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "hm = np.array(hm_data)\n",
    "plt.figure()\n",
    "ax = sns.heatmap(hm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=False, xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.set_title(\"Hashtag overlaps (those who used hashtag A also used hashtag B)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = categorize_users(counters[\"users\"], timespan_d)\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title('Users seen breakdown')\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = categorize_users(susp_ht_users, timespan_d)\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title('Suspicious hashtag users')\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = categorize_users(counters[\"retweeters\"], timespan_d)\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title('Retweeters breakdown')\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = categorize_users(counters[\"retweeted\"], timespan_d)\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title('Retweeted breakdown')\n",
    "plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print activity comparison for some hashtags\n",
    "offset=0\n",
    "max_lines = 8\n",
    "all_x_labels = get_timestamp_range(collect_start, collect_end)\n",
    "targets = [x for x, c in counters[\"hashtags\"].most_common()][offset:]\n",
    "all_plots = []\n",
    "labels = []\n",
    "for target in targets:\n",
    "    if len(labels) >= max_lines:\n",
    "        break\n",
    "    if target in full[\"hashtag_ts_data\"]:\n",
    "        labels.append(target)\n",
    "        plot_data = full[\"hashtag_ts_data\"][target]\n",
    "        counts = plot_data[\"count\"]\n",
    "        times = plot_data[\"time\"]\n",
    "        tc = {}\n",
    "        for i, t in enumerate(times):\n",
    "            tc[t] = counts[i]\n",
    "        fitted = []\n",
    "        for ts in all_x_labels:\n",
    "            if ts in tc:\n",
    "                fitted.append(tc[ts])\n",
    "            else:\n",
    "                fitted.append(0)\n",
    "        all_plots.append(fitted)\n",
    "sns.set(style=\"whitegrid\")\n",
    "x_labels = np.array(all_x_labels).T\n",
    "dates = x_labels\n",
    "values = np.array(all_plots).T\n",
    "data = pd.DataFrame(values, dates, columns=labels)\n",
    "data = data.rolling(7).mean()\n",
    "ax = sns.lineplot(data=data, hue=\"event\", style=\"event\", dashes=False, markers=True, linewidth=1.5)\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print activity comparison for suspicious hashtags\n",
    "offset=0\n",
    "max_lines = 8\n",
    "all_x_labels = get_timestamp_range(collect_start, collect_end)\n",
    "targets = susp_hashtags\n",
    "all_plots = []\n",
    "labels = []\n",
    "if len(targets) > 0:\n",
    "    for target in targets:\n",
    "        if len(labels) >= max_lines:\n",
    "            break\n",
    "        if target in full[\"hashtag_ts_data\"]:\n",
    "            labels.append(target)\n",
    "            plot_data = full[\"hashtag_ts_data\"][target]\n",
    "            counts = plot_data[\"count\"]\n",
    "            times = plot_data[\"time\"]\n",
    "            tc = {}\n",
    "            for i, t in enumerate(times):\n",
    "                tc[t] = counts[i]\n",
    "            fitted = []\n",
    "            for ts in all_x_labels:\n",
    "                if ts in tc:\n",
    "                    fitted.append(tc[ts])\n",
    "                else:\n",
    "                    fitted.append(0)\n",
    "            all_plots.append(fitted)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    x_labels = np.array(all_x_labels).T\n",
    "    dates = x_labels\n",
    "    values = np.array(all_plots).T\n",
    "    data = pd.DataFrame(values, dates, columns=labels)\n",
    "    data = data.rolling(7).mean()\n",
    "    ax = sns.lineplot(data=data, hue=\"event\", style=\"event\", dashes=False, markers=True, linewidth=1.5)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = [x for x, c in counters[\"hashtags\"].most_common(num_plots*2)][1:]\n",
    "min_r = 5\n",
    "dc = \"\"\n",
    "for ht_target in targets:\n",
    "    msg = \"Users that amplified hashtag: #\" + ht_target\n",
    "    msg += \" that used the hashtag at least \" + str(min_r) + \" times\"\n",
    "    if len(dc) > 0:\n",
    "        msg += \" and whose account was created after \" + dc\n",
    "    msg += \".\"\n",
    "    print(msg)\n",
    "    amps = print_hashtag_amplifiers(ht_target, full,  min_retweets=min_r, date_cutoff=dc)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = susp_hashtags\n",
    "min_r = 5\n",
    "dc = \"\"\n",
    "for ht_target in targets:\n",
    "    msg = \"Users that amplified hashtag: #\" + ht_target\n",
    "    msg += \" that used the hashtag at least \" + str(min_r) + \" times\"\n",
    "    if len(dc) > 0:\n",
    "        msg += \" and whose account was created after \" + dc\n",
    "    msg += \".\"\n",
    "    print(msg)\n",
    "    amps = print_hashtag_amplifiers(ht_target, full,  min_retweets=min_r, date_cutoff=dc)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print activity comparison for some users\n",
    "offset=0\n",
    "max_lines = 8\n",
    "all_x_labels = get_timestamp_range(collect_start, collect_end)\n",
    "targets = [x for x, c in counters[\"users\"].most_common()][offset:]\n",
    "all_plots = []\n",
    "labels = []\n",
    "for target in targets:\n",
    "    if len(labels) >= max_lines:\n",
    "        break\n",
    "    if target in full[\"sn_ts_data\"]:\n",
    "        labels.append(target)\n",
    "        plot_data = full[\"sn_ts_data\"][target]\n",
    "        counts = plot_data[\"count\"]\n",
    "        times = plot_data[\"time\"]\n",
    "        tc = {}\n",
    "        for i, t in enumerate(times):\n",
    "            tc[t] = counts[i]\n",
    "        fitted = []\n",
    "        for ts in all_x_labels:\n",
    "            if ts in tc:\n",
    "                fitted.append(tc[ts])\n",
    "            else:\n",
    "                fitted.append(0)\n",
    "        all_plots.append(fitted)\n",
    "if len(labels) > 0:\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    x_labels = np.array(all_x_labels).T\n",
    "    dates = x_labels\n",
    "    values = np.array(all_plots).T\n",
    "    data = pd.DataFrame(values, dates, columns=labels)\n",
    "    data = data.rolling(7).mean()\n",
    "    ax = sns.lineplot(data=data, hue=\"event\", style=\"event\", dashes=False, markers=True, linewidth=1.5)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print activity comparison for some users\n",
    "offset=0\n",
    "max_lines = 8\n",
    "all_x_labels = get_timestamp_range(collect_start, collect_end)\n",
    "targets = [x for x, c in susp_ht_users.most_common()][offset:]\n",
    "all_plots = []\n",
    "labels = []\n",
    "for target in targets:\n",
    "    if len(labels) >= max_lines:\n",
    "        break\n",
    "    if target in full[\"sn_ts_data\"]:\n",
    "        labels.append(target)\n",
    "        plot_data = full[\"sn_ts_data\"][target]\n",
    "        counts = plot_data[\"count\"]\n",
    "        times = plot_data[\"time\"]\n",
    "        tc = {}\n",
    "        for i, t in enumerate(times):\n",
    "            tc[t] = counts[i]\n",
    "        fitted = []\n",
    "        for ts in all_x_labels:\n",
    "            if ts in tc:\n",
    "                fitted.append(tc[ts])\n",
    "            else:\n",
    "                fitted.append(0)\n",
    "        all_plots.append(fitted)\n",
    "if len(labels) > 0:\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    x_labels = np.array(all_x_labels).T\n",
    "    dates = x_labels\n",
    "    values = np.array(all_plots).T\n",
    "    data = pd.DataFrame(values, dates, columns=labels)\n",
    "    data = data.rolling(7).mean()\n",
    "    ax = sns.lineplot(data=data, hue=\"event\", style=\"event\", dashes=False, markers=True, linewidth=1.5)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print retweet activity comparison for some accounts\n",
    "offset=0\n",
    "max_lines = 8\n",
    "all_x_labels = get_timestamp_range(collect_start, collect_end)\n",
    "targets = [x for x, c in counters[\"retweeted\"].most_common()][offset:]\n",
    "all_plots = []\n",
    "labels = []\n",
    "for target in targets:\n",
    "    if len(labels) >= max_lines:\n",
    "        break\n",
    "    if target in full[\"rsn_ts_data\"]:\n",
    "        labels.append(target)\n",
    "        plot_data = full[\"rsn_ts_data\"][target]\n",
    "        counts = plot_data[\"count\"]\n",
    "        times = plot_data[\"time\"]\n",
    "        tc = {}\n",
    "        for i, t in enumerate(times):\n",
    "            tc[t] = counts[i]\n",
    "        fitted = []\n",
    "        for ts in all_x_labels:\n",
    "            if ts in tc:\n",
    "                fitted.append(tc[ts])\n",
    "            else:\n",
    "                fitted.append(0)\n",
    "        all_plots.append(fitted)\n",
    "sns.set(style=\"whitegrid\")\n",
    "x_labels = np.array(all_x_labels).T\n",
    "dates = x_labels\n",
    "values = np.array(all_plots).T\n",
    "data = pd.DataFrame(values, dates, columns=labels)\n",
    "data = data.rolling(7).mean()\n",
    "ax = sns.lineplot(data=data, hue=\"event\", style=\"event\", dashes=False, markers=True, linewidth=1.5)\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print activity comparison for some tweets\n",
    "offset=0\n",
    "max_lines = 8\n",
    "all_x_labels = get_timestamp_range(collect_start, collect_end)\n",
    "targets = [x for x, c in twid_count.most_common()][offset:]\n",
    "all_plots = []\n",
    "labels = []\n",
    "for target in targets:\n",
    "    if len(labels) >= max_lines:\n",
    "        break\n",
    "    if target in full[\"rtwid_ts_data\"]:\n",
    "        tweet_text = twid_text[target].replace(\"\\n\", \" \").replace(\"\\r\", \" \")[:50]\n",
    "        title = target + \"\\n\" + tweet_text\n",
    "        labels.append(title)\n",
    "        plot_data = full[\"rtwid_ts_data\"][target]\n",
    "        counts = plot_data[\"count\"]\n",
    "        times = plot_data[\"time\"]\n",
    "        tc = {}\n",
    "        for i, t in enumerate(times):\n",
    "            tc[t] = counts[i]\n",
    "        fitted = []\n",
    "        for ts in all_x_labels:\n",
    "            if ts in tc:\n",
    "                fitted.append(tc[ts])\n",
    "            else:\n",
    "                fitted.append(0)\n",
    "        all_plots.append(fitted)\n",
    "sns.set(style=\"whitegrid\")\n",
    "x_labels = np.array(all_x_labels).T\n",
    "dates = x_labels\n",
    "values = np.array(all_plots).T\n",
    "data = pd.DataFrame(values, dates, columns=labels)\n",
    "data = data.rolling(7).mean()\n",
    "ax = sns.lineplot(data=data, hue=\"event\", style=\"event\", dashes=False, markers=True, linewidth=1.5)\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This prints the top n tweets seen in the data set (by the number of times we saw them shared)\n",
    "print_tweet_texts(twid_count, twid_text, twid_url, num_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for twid, count in twid_count.most_common(20):\n",
    "    url = twid_url[twid]\n",
    "    tw = Tweet(url)\n",
    "    display(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Most amplified accounts in the dataset.\")\n",
    "amps = print_most_amplified(full, high_vol, include_verified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This partitions the accounts into communities\n",
    "# it requires python-igraph\n",
    "# Note you can use sn_rsn, sn_rep, or sn_men\n",
    "# Depending on what you're looking for\n",
    "clusters = get_communities(sn_rsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I just print out some of the most prominent\n",
    "# accounts in each cluster\n",
    "threshold = high_vol\n",
    "mon_in_cluster = {}\n",
    "cluster_len = {}\n",
    "cluster_retweets = {}\n",
    "for index, names in clusters.items():\n",
    "    if len(names) > 10:\n",
    "        cluster_len[index] = len(names)\n",
    "    top = set()\n",
    "    for x, c in counters[\"retweeted\"].most_common():\n",
    "        if c > 0:\n",
    "            if x in names:\n",
    "                top.add(x)\n",
    "            if len(top) > 10:\n",
    "                break\n",
    "    rtc = 0\n",
    "    for n in names:\n",
    "        if n in rsn_sn:\n",
    "            for sn, count in rsn_sn[n].most_common():\n",
    "                rtc += count\n",
    "    cluster_retweets[index] = rtc\n",
    "    if len(top) > 0:\n",
    "        mon_in_cluster[index] = top\n",
    "summary = Counter()\n",
    "cluster_names = {}\n",
    "for index, count in cluster_len.items():\n",
    "    names = []\n",
    "    if index in mon_in_cluster:\n",
    "        names = mon_in_cluster[index]\n",
    "    print(\"\")\n",
    "    msg = \"Cluster: \" + str(index)\n",
    "    msg += \" [Members: \" + str(count) + \", Retweet count: \" + str(cluster_retweets[index]) + \"]\"\n",
    "    print(msg)\n",
    "    members = Counter()\n",
    "    for n in names:\n",
    "        rtc = 0\n",
    "        if n in rsn_sn:\n",
    "            for s, c in rsn_sn[n].items():\n",
    "                rtc += c\n",
    "        flag = \"\"\n",
    "        if rtc > threshold:\n",
    "            summary[n] = rtc\n",
    "        print(flag + \"https://twitter.com/\" + n + \"\\t(\" + str(rtc) + \")\")\n",
    "        members[n] = rtc\n",
    "    if len(members) > 0:\n",
    "        top_member, top_count = members.most_common(1)[0]\n",
    "        cluster_names[index] = top_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pie chart of the cluster sizes. Labels are derived in the\n",
    "# previous step (the most retweeted account in the cluster)\n",
    "labels = []\n",
    "sizes = []\n",
    "node_count = sum([len(c) for x, c in clusters.items()])\n",
    "num_clusters = len(clusters)\n",
    "other = 0\n",
    "other_c = 0\n",
    "other_rtc = 0\n",
    "named_clusters = set()\n",
    "named_cluster_c = Counter()\n",
    "for x, c in sorted(clusters.items()):\n",
    "    if x in cluster_names:\n",
    "        named_clusters.add(x)\n",
    "        named_cluster_c[x] = cluster_retweets[x]\n",
    "        nc = len(c)\n",
    "        labels.append(\"@\"+cluster_names[x] + \" (\" + str(nc) + \" / \" + str(cluster_retweets[x]) + \")\")\n",
    "        sizes.append(len(c))\n",
    "    else:\n",
    "        other_c += 1\n",
    "        other_rtc += cluster_retweets[x]\n",
    "        other += len(c)\n",
    "if other_c > 0:\n",
    "    labels.append( str(other_c) + \" other clusters (\" + str(other) + \" / \" + str(other_rtc) + \")\")\n",
    "    sizes.append(other)\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax = fig.add_axes((0,0,.5,1))\n",
    "ax.set_title('Cluster distributions')\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=0)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a heatmap of cluster overlaps\n",
    "top_named_clusters = set([x for x, c in named_cluster_c.most_common(20)])\n",
    "overlaps = get_cluster_overlaps_partial(clusters, sn_rsn, top_named_clusters)\n",
    "hm_labels = []\n",
    "hm_indices = []\n",
    "hm_data = []\n",
    "for label, oc in sorted(overlaps.items()):\n",
    "    hm_labels.append(cluster_names[label][:8])\n",
    "    hm_indices.append(label)   \n",
    "for index in hm_indices:\n",
    "    row = [c for x, c in sorted(overlaps[index].items())]\n",
    "    hm_data.append(row)\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "hm = np.array(hm_data)\n",
    "plt.figure()\n",
    "ax = sns.heatmap(hm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=False, xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.set_title(\"Cluster overlaps (top 20 clusters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Found \" + str(len(summary)) + \" influencers from clustering.\")\n",
    "print_sn_counter(summary, len(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_summary = [x for x, c in summary.most_common()]\n",
    "for target in top_summary[:5]:\n",
    "    print(\"\")\n",
    "    print(\"Full analysis for account: \" + target)\n",
    "    print(\"=====================================\")\n",
    "    print(\"\")\n",
    "    # Find the cluster that includes _target_ account\n",
    "    selected_cluster = get_cluster_for_sn(target, clusters)\n",
    "    print(\"There were \" + str(len(selected_cluster)) + \" accounts in the cluster with \" + target)\n",
    "\n",
    "    # Get details of all accounts in that cluster\n",
    "    cluster_details = []\n",
    "    for sn in selected_cluster:\n",
    "        if sn in sn_details:\n",
    "            cluster_details.append(sn_details[sn])\n",
    "    print(\"Found details for \" + str(len(cluster_details)) + \" accounts.\")\n",
    "\n",
    "    # Save those userids and details\n",
    "    if save_data == True:\n",
    "        # Get the userids of those users if the accounts are\n",
    "        # not verified or protected\n",
    "        cluster_ids = set()\n",
    "        for d in cluster_details:\n",
    "            valid = True\n",
    "            if d[\"protected\"] == True:\n",
    "                valid = False\n",
    "            if d[\"verified\"] == True:\n",
    "                valid = False\n",
    "            if valid == True:\n",
    "                cluster_ids.add(d[\"id_str\"])\n",
    "        print(\"Retrieved \" + str(len(cluster_ids)) + \" IDs from data.\")\n",
    "        print(\"\")\n",
    "        with open(os.path.join(dirname, \"ids_cluster_\" + target + \".txt\"), \"w\") as f:\n",
    "            for id_str in cluster_ids:\n",
    "                f.write(id_str+\"\\n\")\n",
    "        save_json(list(cluster_ids), os.path.join(dirname, \"cluster_\" + target + \".json\"))\n",
    "        save_json(cluster_details, os.path.join(dirname, \"details_cluster_\" + target + \".json\"))\n",
    "    \n",
    "    # Show account age distribution\n",
    "    cluster_acct_ages = Counter()\n",
    "    for d in cluster_details:\n",
    "        if \"created_at\" in d:\n",
    "            ca = d[\"created_at\"]\n",
    "            yr = ca[-4:]\n",
    "            mon = md[ca[4:7]]\n",
    "            q = \"\"\n",
    "            for qname, qvals in quarters.items():\n",
    "                if int(mon) in qvals:\n",
    "                    q = qname\n",
    "            day = ca[8:10]\n",
    "            ds = str(yr) + \"-\" + q\n",
    "            cluster_acct_ages[ds] += 1\n",
    "    plot_data = {}\n",
    "    plot_data[\"labels\"] = []\n",
    "    plot_data[\"counts\"] = []\n",
    "    for label, count in sorted(cluster_acct_ages.items(), reverse=True):\n",
    "        plot_data[\"labels\"].append(label)\n",
    "        plot_data[\"counts\"].append(count)\n",
    "    plot_data = trim_plot_data(plot_data, 0, 50)\n",
    "    height = len(plot_data[\"counts\"])/3\n",
    "    sns.set(rc={'figure.figsize':(20,height)})\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    ax = sns.barplot(x=\"counts\", y=\"labels\", palette=\"husl\", data=plot_data)\n",
    "    for i, v in enumerate(plot_data[\"counts\"]):\n",
    "        pad = min(1.0, v/100)\n",
    "        ax.text(v+pad, i+0.25, str(v), fontweight='bold')\n",
    "    ax.set_title(\"Account ages in cluster: \" + target)\n",
    "    \n",
    "    # Show some hashtags used by the cluster\n",
    "    cluster_hts = Counter()\n",
    "    sn_hashtag = full[\"sn_hashtag\"]\n",
    "    for sn in selected_cluster:\n",
    "        if sn in sn_hashtag:\n",
    "            for ht, c in sn_hashtag[sn].items():\n",
    "                cluster_hts[ht] += c\n",
    "\n",
    "    plot_data = {}\n",
    "    plot_data[\"labels\"] = []\n",
    "    plot_data[\"sizes\"] = []\n",
    "\n",
    "    n = 30\n",
    "    other = 0\n",
    "    otherc = 0\n",
    "    for ht, c in cluster_hts.most_common():\n",
    "        if len(plot_data[\"labels\"]) <= n:\n",
    "            plot_data[\"labels\"].append(\"#\" + ht)\n",
    "            plot_data[\"sizes\"].append(c)\n",
    "        else:\n",
    "            otherc += 1\n",
    "            other += c\n",
    "    plot_data[\"labels\"].append(\"Other (\" + str(other) + \")\")\n",
    "    plot_data[\"sizes\"].append(other)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,7))\n",
    "    ax = fig.add_axes((0,0,.5,1))\n",
    "    ax.set_title(target + ' cluster hashtag breakdown')\n",
    "    plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=0)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    cluster_snc = Counter()\n",
    "    users = counters[\"users\"]\n",
    "    for sn in selected_cluster:\n",
    "        if sn in users:\n",
    "            cluster_snc[sn] = users[sn]\n",
    "    plot_data = categorize_users(cluster_snc, timespan_d)\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.add_axes((0,0,.5,1))\n",
    "    ax.set_title(target + ' retweet breakdown')\n",
    "    plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=140)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show some tweets published by the cluster\n",
    "    print(\"\")\n",
    "    print(\"Top tweets published by cluster including: \" + target)\n",
    "    print(\"==================================================\")\n",
    "    print(\"\")\n",
    "    twidc = Counter()\n",
    "    sn_twid = full[\"sn_twid\"]\n",
    "    for sn in selected_cluster:\n",
    "        if sn in sn_twid:\n",
    "            for twid, c in sn_twid[sn].items():\n",
    "                twidc[twid] += c\n",
    "    for twid, count in twidc.most_common(10):\n",
    "        url = twid_url[twid]\n",
    "        text = twid_text[twid]\n",
    "        print(str(count) + \"\\t\" + url + \"\\t[\" + twid + \"]\")\n",
    "        display(Tweet(url))\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Top URLs published by cluster including: \" + target)\n",
    "    print(\"==================================================\")\n",
    "    print(\"\")\n",
    "    # Show some urls published by the cluster\n",
    "    urlc = Counter()\n",
    "    sn_url = full[\"sn_url\"]\n",
    "    for sn in selected_cluster:\n",
    "        if sn in sn_url:\n",
    "            for url, c in sn_url[sn].items():\n",
    "                urlc[url] += c\n",
    "    print_counter(urlc, num_counters)\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Accounts retweeted by cluster including: \" + target)\n",
    "    print(\"==================================================\")\n",
    "    print(\"\")\n",
    "    clrtw = Counter()\n",
    "    for sn in selected_cluster:\n",
    "        if sn in sn_rsn:\n",
    "            for x, c in sn_rsn[sn].items():\n",
    "                clrtw[x] += c\n",
    "    print_sn_counter(clrtw, num_counters)\n",
    "    print(\"\")\n",
    "    \n",
    "    # Get details for the list of users that retweeted _target_\n",
    "    print(\"\")\n",
    "    print(\"Retweet analysis for target: \" + target)\n",
    "    print(\"=========================================\")\n",
    "    print(\"\")\n",
    "    rtw = rsn_sn[target]\n",
    "    rlist = [x for x, c in rtw.items()]\n",
    "    print(\"Found  \" + str(len(rlist)) + \" accounts that retweeted \" + target)\n",
    "\n",
    "    rdetails = []\n",
    "    for sn in rlist:\n",
    "        if sn in sn_details:\n",
    "            rdetails.append(sn_details[sn])\n",
    "    print(\"Found details for \" + str(len(rdetails)) + \" accounts.\")\n",
    "\n",
    "    # Save those userids and details\n",
    "    if save_data == True:\n",
    "        # Get the userids of those users if the accounts are\n",
    "        # not verified or protected\n",
    "        relids = set()\n",
    "        for d in rdetails:\n",
    "            valid = True\n",
    "            if d[\"protected\"] == True:\n",
    "                valid = False\n",
    "            if d[\"verified\"] == True:\n",
    "                valid = False\n",
    "            if valid == True:\n",
    "                relids.add(d[\"id_str\"])\n",
    "        print(\"Retrieved \" + str(len(relids)) + \" IDs from data.\")\n",
    "        with open(os.path.join(dirname, \"ids_retweeted_\" + target + \".txt\"), \"w\") as f:\n",
    "            for id_str in relids:\n",
    "                f.write(id_str+\"\\n\")\n",
    "        save_json(list(relids), os.path.join(dirname, \"retweeted_\" + target + \".json\"))\n",
    "        save_json(rdetails, os.path.join(dirname, \"details_retweeted_\" + target + \".json\"))\n",
    "    \n",
    "    plot_data = categorize_users(rsn_sn[target], timespan_d)\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.add_axes((0,0,.5,1))\n",
    "    ax.set_title(target + ' retweet breakdown')\n",
    "    plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=140)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    rt_hts = Counter()\n",
    "    sn_hashtag = full[\"sn_hashtag\"]\n",
    "    for sn in rlist:\n",
    "        if sn in sn_hashtag:\n",
    "            for ht, c in sn_hashtag[sn].items():\n",
    "                cluster_hts[ht] += c\n",
    "\n",
    "    plot_data = {}\n",
    "    plot_data[\"labels\"] = []\n",
    "    plot_data[\"sizes\"] = []\n",
    "\n",
    "    n = 30\n",
    "    other = 0\n",
    "    otherc = 0\n",
    "    for ht, c in cluster_hts.most_common():\n",
    "        if len(plot_data[\"labels\"]) <= n:\n",
    "            plot_data[\"labels\"].append(\"#\" + ht)\n",
    "            plot_data[\"sizes\"].append(c)\n",
    "        else:\n",
    "            otherc += 1\n",
    "            other += c\n",
    "    plot_data[\"labels\"].append(\"Other (\" + str(other) + \")\")\n",
    "    plot_data[\"sizes\"].append(other)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.add_axes((0,0,.5,1))\n",
    "    ax.set_title(target + ' rewteeters hashtag breakdown')\n",
    "    plt.pie(plot_data[\"sizes\"], labels=plot_data[\"labels\"], autopct='%1.1f%%', startangle=0)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show account age distribution\n",
    "    cluster_acct_ages = Counter()\n",
    "    for d in rdetails:\n",
    "        if \"created_at\" in d:\n",
    "            ca = d[\"created_at\"]\n",
    "            yr = ca[-4:]\n",
    "            mon = md[ca[4:7]]\n",
    "            q = \"\"\n",
    "            for qname, qvals in quarters.items():\n",
    "                if int(mon) in qvals:\n",
    "                    q = qname\n",
    "            day = ca[8:10]\n",
    "            ds = str(yr) + \"-\" + q\n",
    "            cluster_acct_ages[ds] += 1\n",
    "    plot_data = {}\n",
    "    plot_data[\"labels\"] = []\n",
    "    plot_data[\"counts\"] = []\n",
    "    for label, count in sorted(cluster_acct_ages.items(), reverse=True):\n",
    "        plot_data[\"labels\"].append(label)\n",
    "        plot_data[\"counts\"].append(count)\n",
    "    plot_data = trim_plot_data(plot_data, 0, 50)\n",
    "    height = len(plot_data[\"counts\"])/3\n",
    "    sns.set(rc={'figure.figsize':(20,height)})\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    ax = sns.barplot(x=\"counts\", y=\"labels\", palette=\"husl\", data=plot_data)\n",
    "    for i, v in enumerate(plot_data[\"counts\"]):\n",
    "        pad = min(1.0, v/100)\n",
    "        ax.text(v+pad, i+0.25, str(v), fontweight='bold')\n",
    "    ax.set_title(\"Ages of accounts that retweeted: \" + target)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Accounts retweeted by accounts that retweeted: \" + target)\n",
    "    print(\"==================================================\")\n",
    "    print(\"\")\n",
    "    rrtw = Counter()\n",
    "    for sn in rlist:\n",
    "        if sn in sn_rsn:\n",
    "            for x, c in sn_rsn[sn].items():\n",
    "                rrtw[x] += c\n",
    "    print_sn_counter(rrtw, num_counters)\n",
    "    print(\"\")   \n",
    "    \n",
    "    # Show some tweets published by retweeters of target\n",
    "    print(\"\")\n",
    "    print(\"Top tweets published by retweeters of: \" + target)\n",
    "    print(\"==================================================\")\n",
    "    print(\"\")\n",
    "    twidc = Counter()\n",
    "    sn_twid = full[\"sn_twid\"]\n",
    "    for sn in rlist:\n",
    "        if sn in sn_twid:\n",
    "            for twid, c in sn_twid[sn].items():\n",
    "                twidc[twid] += c\n",
    "    for twid, count in twidc.most_common(10):\n",
    "        url = twid_url[twid]\n",
    "        text = twid_text[twid]\n",
    "        print(str(count) + \"\\t\" + url + \"\\t[\" + twid + \"]\")\n",
    "        display(Tweet(url))\n",
    "    \n",
    "    # Show some urls published by the retweeters of target\n",
    "    print(\"\")\n",
    "    print(\"URLs published by retweeters of: \" + target)\n",
    "    print(\"==================================================\")\n",
    "    print(\"\")\n",
    "    urlc = Counter()\n",
    "    sn_url = full[\"sn_url\"]\n",
    "    for sn in rlist:\n",
    "        if sn in sn_url:\n",
    "            for url, c in sn_url[sn].items():\n",
    "                urlc[url] += c\n",
    "    print_counter(urlc, num_counters)\n",
    "    \n",
    "    print(\"\")\n",
    "    min_r = 5\n",
    "    dc = \"\"\n",
    "    msg = \"Users that retweeted \" + target + \" (\" + str(len(rsn_sn[target])) + \")\"\n",
    "    msg += \" at least \" + str(min_r) + \" times\"\n",
    "    if len(dc) > 0:\n",
    "        msg += \" and whose account was created after \" + dc\n",
    "    msg += \".\"\n",
    "    print(msg)\n",
    "    amps = print_target_amplifiers(target, full, min_retweets=min_r, date_cutoff=dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
